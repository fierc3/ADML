# Feature Engineering
- Manipulation of raw data for better performance / results


## Data keywords
- attributes/featires
	- Are the attributes of data for example: color, shape etc,
- Tabular Data
	- Every row is a data entry and considered as a data point
	- When numerical, the data point can be interpreted with multi dimensional cvector in a feature space
	- Distance between 2 spaces is the similarity
	- Also known as Panel Data (python pandas name it Panel Data)
- Time Series Data
	- have choronoglogical order -> sequence has to be complete to interpret.
- Image Data
	- tabular data
	- color -> represented by rgb
	- black white just one value
- Text data
	- Raw data usually not ideal for ml. Needs to be improved in _Feature Engineering_


## DQA & Data cleaning
Step before Feature engineering. Sie [1. Data Classfication]


## Engineering New Features
### Grouping
Group data with similar categorical data.
### Binning
Change numerical value to ranges "grouping" them in bins
### De-skew Data
![[Pasted image 20220127133800.png]]
### Kernel Trick
Project data into higher dimension to analyze features
### Expert Knowledge
Know things about the domain you are feature engineering for
### Transform features
Display multiple features dependencies
### Expert Features in Time Series
Important to make conclusions


## Image Data & Computer Vision Applications
### Edges
Edges are very important to recognize shapes in pictures and thus features.

#### Edge Detection
- option 1 can be calculated with the gardient
-  option 2: move picture by one pixel -> subtract from original

### Image Segmentation
- mit K-Means clustering wrden Bilder in Segmetn aufgeteilt

![[Pasted image 20220127134806.png]]

### Image Denoising
To flatten the image, the MEAN of each neighbor can be assigned.

### Histogram Equalization
Reassign pixel values to make it sharper
![[Pasted image 20220127135305.png]]

### Scale Invariant Feature Transform - SIFT
Algorithm to recognice keypoints and local features.

### Feature learning in Computer Vision
Trend towards using deep neural networks



## Text Data & Language Applications
Natural Language Processing (NLP) is a mix of CS and Lingustics.

Difficulties
- context dependant meaning
- rare words

### Linguistic Feature Engineering
how to prepare text
1. Tokenization (words, interpunktion)
2. Stop Word Removal (removal of fullwords and less important tokens)
3. Stemming & Lemmatization (Words in base form -> WÃ¶rter Wort + in infinitv)
4. Part of Speech tagging (label verbs, nouns)
5. Syntax (Text parsing, Grammar, context)


### Text vectorization
static features are analyzed and created numerically.
Benefits
- Text can be analyzed with algorithms
- distance / similairity

### One-Hot-Encoding
marking when a word is used
![[Pasted image 20220127140055.png]]

### Bag-of-Words
count of references
![[Pasted image 20220127140316.png]]
Allows easy calcualtions of how different 2 texts are

### Term Frequency-Inverse Document Frequency (TF-IDF)
Famous text vectorizing alorithm.
created with 2 terms
- Term frequency
- Inverse Doucment Frequency (IDF)
